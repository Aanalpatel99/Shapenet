{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_files(data_path, recursive=True):\n",
    "    \n",
    "    # Retrieve OBJ files from the data path\n",
    "    obj_files = [file for file in glob.glob(data_path + r\"\\**\\*.obj\", recursive=recursive)]\n",
    "    print(f\"Found {len(obj_files)} OBJ files.\")\n",
    "    return obj_files\n",
    "\n",
    "def save_npy_array_from_obj(obj_files, voxel_shape, voxel_resolution=0.025, save_npy=True, npy_filename='voxel_grids'):\n",
    "    \n",
    "    # Loop through the OBJ files and initialize an empty array that will contain np arrays\n",
    "    print(\"Starting the pipeline...\")\n",
    "    np_arrays = []\n",
    "    for i, obj_file in enumerate(obj_files):\n",
    "    \n",
    "        # Read the mesh from the OBJ file\n",
    "        mesh = trimesh.load(obj_file, force='mesh')\n",
    "        \n",
    "        # Create a voxel grid\n",
    "        voxelized = mesh.voxelized(pitch=voxel_resolution)\n",
    "        voxelized = voxelized.revoxelized(shape=voxel_shape)\n",
    "        voxel_matrix = voxelized.matrix\n",
    "        \n",
    "        # Reshape the array to (voxel_shape, 1)\n",
    "        new_shape = tuple(list(voxel_shape) + [1])\n",
    "        voxel_matrix = voxel_matrix.reshape(new_shape)\n",
    "        np_arrays.append(voxel_matrix)\n",
    "        print(f\"{i+1}\", end=\" \")\n",
    "    \n",
    "    # Save the voxel matrix as an NPY file\n",
    "    np_arrays_stacked = np.stack(tuple(np_arrays), axis=0)\n",
    "    print(f\"Final NumPy array shape: {np_arrays_stacked.shape}\")\n",
    "\n",
    "    # Save the NumPy array as an NPY file if specified, otherwise, return the array\n",
    "    if save_npy:\n",
    "        np.save(npy_filename + \".npy\", np_arrays_stacked)\n",
    "        return None\n",
    "    return np_arrays_stacked\n",
    "\n",
    "# Save the paths of each of the OBJ files into a list\n",
    "DATA_PATH = r\"C:\\Users\\aanal\\Documents\\sem3\\nureal_network_and_deep_learning\\Project\\Data\"\n",
    "obj_files = get_obj_files(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert OBJ files into voxel grids, and save them into a Numpy array\n",
    "save_npy_array_from_obj(obj_files, (32, 32, 32), voxel_resolution=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_names(data_path):\n",
    "\n",
    "    # Initialize an empty array and loop through the folders within data path\n",
    "    category_names = []\n",
    "    for folder in os.scandir(data_path):\n",
    "\n",
    "        # if the folder name starts with a number then it's a category name\n",
    "        folder_basename = os.path.basename(folder.path)\n",
    "        if folder.is_dir() and folder_basename[0].isdigit():\n",
    "            category_names.append(folder_basename)\n",
    "    return category_names\n",
    "\n",
    "categories = get_category_names(r\"C:\\Users\\aanal\\Documents\\sem3\\nureal_network_and_deep_learning\\Project\\Data\")\n",
    "print(f\"We have {len(categories)} categories.\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_npy_array_from_obj_per_category(data_path, voxel_shape, voxel_resolution=0.025):\n",
    "\n",
    "    # Get the category names (55)\n",
    "    categories = get_category_names(data_path)\n",
    "    print(f\"Found {len(categories)} categories.\")\n",
    "\n",
    "    # Loop through the categories\n",
    "    for i, category in enumerate(categories):\n",
    "        print(f\"================ Starting process for category #{i+1}, name: {category} ================\")\n",
    "\n",
    "        # Set the category data path and retrieve all obj files\n",
    "        category_path = data_path + '\\\\' + category\n",
    "        obj_files = get_obj_files(category_path, recursive=True)\n",
    "        \n",
    "        # Convert OBJ files into voxel grids, and save them into a Numpy array\n",
    "        save_npy_array_from_obj(obj_files, voxel_shape, voxel_resolution, save_npy=True, npy_filename=category+\"_voxels\")\n",
    "\n",
    "data_path = r\"C:\\Users\\aanal\\Documents\\sem3\\nureal_network_and_deep_learning\\Project\\Data\"\n",
    "save_npy_array_from_obj_per_category(data_path, (32, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_images_from_obj_files(obj_files, renderer_git_path, n_views, output_path, randomize_view, start_id=0):\n",
    "    \n",
    "    # Save current path and change to the stanford-shapenet-renderer tool path\n",
    "    current_path = os.getcwd()\n",
    "    os.chdir(renderer_git_path)\n",
    "    \n",
    "    # For each OBJ file, generate the images using the renderer tool\n",
    "    print(\"Starting the pipeline (generating images)...\")\n",
    "    for i, obj_file in enumerate(obj_files):\n",
    "        print(f\"{i+1}\", end=\" \")\n",
    "        command_str = f'blender --background --python render_blender.py -- --views {n_views} --id_render {start_id+i+1} --randomize_view {int(randomize_view)} --output_folder {output_path} {obj_file}'\n",
    "        os_return = os.system(command_str)\n",
    "        \n",
    "        # Check if process was executed succesfully\n",
    "        if os_return != 0:\n",
    "            print(f\"Error... os returned: {os_return}\")\n",
    "            break\n",
    "            \n",
    "    # Return to the original path\n",
    "    os.chdir(current_path)\n",
    "\n",
    "def render_images_per_category(categories, n_views, renderer_path, data_path, output_path, randomize_view=False):\n",
    "    print(f\"Found {len(categories)} categories.\")\n",
    "    \n",
    "    # Loop through each of the categories\n",
    "    for i, category in enumerate(categories):\n",
    "        print(f\"\\n================ Starting process for category #{i+1}, name: {category} ================\")\n",
    "\n",
    "        # Set the category data path and retrieve all obj files\n",
    "        category_path = data_path + '\\\\' + category\n",
    "        obj_files = get_obj_files(category_path, recursive=True)\n",
    "        \n",
    "        # Render the images according to the parameters\n",
    "        render_images_from_obj_files(obj_files, renderer_path, n_views, output_path + \"/\" + category, randomize_view)\n",
    "\n",
    "data_path = r\"C:\\Users\\aanal\\Documents\\sem3\\nureal_network_and_deep_learning\\Project\\Data\"\n",
    "renderer_path = r\"C:\\Users\\aanal\\Documents\\sem3\\nureal_network_and_deep_learning\\Project\\stanford-shapenet-renderer\"\n",
    "output_path = \"/Users/aanal/Documents/sem3/nureal_network_and_deep_learning/Project/op/\"\n",
    "render_images_per_category(categories, 10, renderer_path, data_path, output_path, randomize_view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
